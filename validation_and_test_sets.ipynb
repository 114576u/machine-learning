{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2sLxSlb7ZncKFt3tOu0Ms",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/114576u/machine-learning/blob/master/validation_and_test_sets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EsebNarhHMG_"
      },
      "outputs": [],
      "source": [
        "# This is obtained from \n",
        "# https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/validation_and_test_sets.ipynb?utm_source=mlcc&utm_campaign=colab-external&utm_medium=referral&utm_content=validation_tf2-colab&hl=en\n",
        "# in the context of the machine learning training from\n",
        "# https://developers.google.com/machine-learning/crash-course/first-steps-with-tensorflow/programming-exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation Sets and Test Sets\n",
        "The previous Colab exercises evaluated the trained model against the training set, which does not provide a strong signal about the quality of your model. In this Colab, you'll experiment with validation sets and test sets.\n",
        "\n",
        "# Learning objectives\n",
        "After doing this Colab, you'll know how to do the following:\n",
        "\n",
        "Split a training set into a smaller training set and a validation set.\n",
        "Analyze deltas between training set and validation set results.\n",
        "Test the trained model with a test set to determine whether your trained model is overfitting.\n",
        "Detect and fix a common training problem.\n",
        "The dataset\n",
        "As in the previous exercise, this exercise uses the California Housing dataset to predict the median_house_value at the city block level. Like many \"famous\" datasets, the California Housing Dataset actually consists of two separate datasets, each living in separate .csv files:\n",
        "\n",
        "The training set is in california_housing_train.csv.\n",
        "The test set is in california_housing_test.csv.\n",
        "You'll create the validation set by dividing the downloaded training set into two parts:\n",
        "\n",
        "a smaller training set\n",
        "a validation set"
      ],
      "metadata": {
        "id": "ITl_N_u6IBuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format"
      ],
      "metadata": {
        "id": "FagRqV7yIHb0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# we are now loading the datasets to use:\n",
        "# train_df => contains the training set\n",
        "# test_df  => contains the test set\n",
        "\n",
        "train_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
        "test_df  = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")"
      ],
      "metadata": {
        "id": "0kmPBa4rIawZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# we are scaling the value for median_house_value:\n",
        "scale_factor = 1000.0\n",
        "\n",
        "# scale the training set's label\n",
        "train_df[\"median_house_value\"] /= scale_factor\n",
        "\n",
        "# scale the test set's label\n",
        "test_df[\"median_house_value\"] /= scale_factor"
      ],
      "metadata": {
        "id": "5T6g4NXYIvrD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# creating now the function to build the model (model's topography)\n",
        "def build_model(my_learning_rate):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # most simple tf.keras models are sequential\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # add one linear layer to the model to yield a simple linear regression\n",
        "  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))\n",
        "\n",
        "  # compile the model topography into code that TensorFlow can efficiently execute.\n",
        "  # Configure training to minimize the model's mean squared error.\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate), \n",
        "                loss=\"mean_squared_error\", \n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "  return model\n",
        "\n",
        "print(\"Defined the build_model function.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5kjvkKIJElW",
        "outputId": "d51cdff8-3b26-4387-c8b7-ade09c482be5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined the build_model function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# define the train model\n",
        "def train_model(model, df, feature, label, my_epochs, my_batch_size=None, my_validation_split=0.1):\n",
        "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
        "\n",
        "  history = model.fit(x=df[feature],\n",
        "                      y=df[label],\n",
        "                      batch_size=my_batch_size,\n",
        "                      epochs=my_epochs,\n",
        "                      validation_split=my_validation_split)\n",
        "  \n",
        "  # gather the model's trained weight and bias.\n",
        "  trained_weight = model.get_weights()[0]\n",
        "  trained_bias = model.get_weights()[1]\n",
        "\n",
        "  # the list of epochs is stored separately from the rest of history\n",
        "  epochs = history.epoch\n",
        "\n",
        "  # isolate the root mean squared root for each epoch\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return epochs, rmse, history.history\n",
        "\n",
        "print(\"Defined the train_model function.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaw9MwSu2-DZ",
        "outputId": "f3dfe5b1-78c0-4069-ba33-ab2901d99dcb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined the train_model function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# we define now a plotting function, to show the loss vs epochs for both the training set and the validation set\n",
        "def plot_the_loss_curve(epochs, mae_training, mae_validation):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Root Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs[1:], mae_training[1:], label=\"Training Loss\")\n",
        "  plt.plot(epochs[1:], mae_validation[1:], label=\"Validation Loss\")\n",
        "  plt.legend()\n",
        "\n",
        "  # we are not going to plot the first epoch, since the loss on the first epoch is often substantially greater than the loss for other epochs\n",
        "  merged_mae_lists = mae_training[1:] + mae_validation[1:]\n",
        "  highest_loss = max(merged_mae_lists)\n",
        "  lowest_loss = min(merged_mae_lists)\n",
        "  delta = highest_loss - lowest_loss\n",
        "  print(delta)\n",
        "\n",
        "  top_of_y_axis = highest_loss + (delta * 0.05)\n",
        "  bottom_of_y_axis = lowest_loss - (delta * 0.05)\n",
        "\n",
        "  plt.ylim([bottom_of_y_axis, top_of_y_axis])\n",
        "  plt.show()\n",
        "\n",
        "print(\"Defined the plot_the_loss_curve function.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c2IHzHz_EIi",
        "outputId": "e419a9a5-a045-4184-b9fa-69c859e78c93"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined the plot_the_loss_curve function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment with the validation split\n",
        "In the following code cell, you'll see a variable named **validation_split**, which we've initialized at 0.2. The validation_split variable specifies the proportion of the original training set that will serve as the validation set. The original training set contains 17,000 examples. Therefore, a validation_split of 0.2 means that:\n",
        "\n",
        "17,000 * 0.2 ~= 3,400 examples will become the validation set.\n",
        "17,000 * 0.8 ~= 13,600 examples will become the new training set.\n",
        "\n",
        "The following code builds a model, trains it on the training set, and evaluates the built model on both:\n",
        "*   The training set.\n",
        "*   The validation set.\n",
        "\n",
        "If the data in the training set is similar to the data in the validation set, then the two loss curves and the final loss values should be almost identical. However, the loss curves and final loss values are not almost identical. Hmm, that's odd.\n",
        "\n",
        "Experiment with two or three different values of validation_split. Do different values of validation_split fix the problem?"
      ],
      "metadata": {
        "id": "Bm1lGWZKekBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# the following parameters are the hyperparameters\n",
        "learning_rate = 0.08\n",
        "epochs = 30\n",
        "batch_size = 100\n",
        "\n",
        "# split the original training set into a reduced training set and a validation set\n",
        "validation_split = 0.4    # jpl::splitting with 0.2 still gives high diffs, but increasing into 0.4, gives very good results\n",
        "\n",
        "# identify the feature and the label\n",
        "my_feature = \"median_income\"    # the median income on a specific city block\n",
        "my_label   = \"median_house_value\" # the median house value on a specific city block\n",
        "# that is, you are going to create a model that predicts house value based solely on the neighborhood's median income\n",
        "\n",
        "# invoke the function to build and train the model\n",
        "my_model = build_model(learning_rate)\n",
        "epochs, rmse, history = train_model(my_model, train_df, my_feature, \n",
        "                                    my_label, epochs, batch_size,\n",
        "                                    validation_split)\n",
        "\n",
        "plot_the_loss_curve(epochs, \n",
        "                    history[\"root_mean_squared_error\"],\n",
        "                    history[\"val_root_mean_squared_error\"]\n",
        "                    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N6mmzVPVe6UC",
        "outputId": "323df2b7-d9ae-4110-baa6-a20072cd79d3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "102/102 [==============================] - 1s 4ms/step - loss: 43862.4766 - root_mean_squared_error: 209.4337 - val_loss: 35230.4219 - val_root_mean_squared_error: 187.6977\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 29632.1797 - root_mean_squared_error: 172.1400 - val_loss: 23041.2754 - val_root_mean_squared_error: 151.7935\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 18976.0371 - root_mean_squared_error: 137.7535 - val_loss: 14251.5293 - val_root_mean_squared_error: 119.3798\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 11805.5762 - root_mean_squared_error: 108.6535 - val_loss: 8945.3496 - val_root_mean_squared_error: 94.5799\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 8082.1064 - root_mean_squared_error: 89.9005 - val_loss: 6907.6890 - val_root_mean_squared_error: 83.1125\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7186.6602 - root_mean_squared_error: 84.7742 - val_loss: 6793.3237 - val_root_mean_squared_error: 82.4216\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7160.8096 - root_mean_squared_error: 84.6216 - val_loss: 6797.3228 - val_root_mean_squared_error: 82.4459\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7157.3042 - root_mean_squared_error: 84.6009 - val_loss: 6802.7202 - val_root_mean_squared_error: 82.4786\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7154.4932 - root_mean_squared_error: 84.5842 - val_loss: 6807.9272 - val_root_mean_squared_error: 82.5102\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7152.5171 - root_mean_squared_error: 84.5726 - val_loss: 6810.2070 - val_root_mean_squared_error: 82.5240\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7149.5059 - root_mean_squared_error: 84.5547 - val_loss: 6818.7266 - val_root_mean_squared_error: 82.5756\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7149.8306 - root_mean_squared_error: 84.5567 - val_loss: 6817.4517 - val_root_mean_squared_error: 82.5679\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7148.4609 - root_mean_squared_error: 84.5486 - val_loss: 6822.2354 - val_root_mean_squared_error: 82.5968\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7146.7114 - root_mean_squared_error: 84.5382 - val_loss: 6825.3628 - val_root_mean_squared_error: 82.6158\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7145.7129 - root_mean_squared_error: 84.5323 - val_loss: 6830.7324 - val_root_mean_squared_error: 82.6482\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7146.9316 - root_mean_squared_error: 84.5395 - val_loss: 6830.6948 - val_root_mean_squared_error: 82.6480\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7147.0928 - root_mean_squared_error: 84.5405 - val_loss: 6831.6860 - val_root_mean_squared_error: 82.6540\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7147.8237 - root_mean_squared_error: 84.5448 - val_loss: 6832.1216 - val_root_mean_squared_error: 82.6566\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7146.6362 - root_mean_squared_error: 84.5378 - val_loss: 6833.6167 - val_root_mean_squared_error: 82.6657\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 7145.4297 - root_mean_squared_error: 84.5306 - val_loss: 6834.6973 - val_root_mean_squared_error: 82.6722\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7147.2920 - root_mean_squared_error: 84.5417 - val_loss: 6835.4331 - val_root_mean_squared_error: 82.6767\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7146.3975 - root_mean_squared_error: 84.5364 - val_loss: 6837.0518 - val_root_mean_squared_error: 82.6865\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7146.8237 - root_mean_squared_error: 84.5389 - val_loss: 6838.3345 - val_root_mean_squared_error: 82.6942\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7146.6885 - root_mean_squared_error: 84.5381 - val_loss: 6838.5190 - val_root_mean_squared_error: 82.6953\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7147.0366 - root_mean_squared_error: 84.5401 - val_loss: 6839.2329 - val_root_mean_squared_error: 82.6997\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7145.9521 - root_mean_squared_error: 84.5337 - val_loss: 6838.6089 - val_root_mean_squared_error: 82.6959\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7145.7554 - root_mean_squared_error: 84.5326 - val_loss: 6840.1060 - val_root_mean_squared_error: 82.7049\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7146.3726 - root_mean_squared_error: 84.5362 - val_loss: 6839.5728 - val_root_mean_squared_error: 82.7017\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7146.0586 - root_mean_squared_error: 84.5344 - val_loss: 6840.6343 - val_root_mean_squared_error: 82.7081\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 7146.4336 - root_mean_squared_error: 84.5366 - val_loss: 6840.4795 - val_root_mean_squared_error: 82.7072\n",
            "89.71837615966797\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Determine why the loss curves differ\n",
        "No matter how you split the training set and the validation set, the loss curves differ significantly. Evidently, the data in the training set isn't similar enough to the data in the validation set. Counterintuitive? Yes, but this problem is actually pretty common in machine learning.\n",
        "\n",
        "Your task is to determine why the loss curves aren't highly similar. As with most issues in machine learning, the problem is rooted in the data itself. To solve this mystery of why the training set and validation set aren't almost identical, write a line or two of pandas code in the following code cell. Here are a couple of hints:\n",
        "\n",
        "The previous code cell split the original training set into:\n",
        "a reduced training set (the original training set - the validation set)\n",
        "the validation set\n",
        "By default, the pandas head method outputs the first 5 rows of the DataFrame. To see more of the training set, specify the n argument to head and assign a large positive integer to n."
      ],
      "metadata": {
        "id": "F6-3n2ckkv-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# examine examples 0 through 4 and examples 995 through 999 of the training set\n",
        "train_df.head(1000)\n",
        "\n",
        "# the original training set is sorted by longitude\n",
        "# Apparently, longitude influences the relationship of total_rooms to median_house_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "crCNg6zHk-F0",
        "outputId": "def3363a-379b-467e-e221-cd9c490f816d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0       -114.3      34.2                15.0       5612.0          1283.0   \n",
              "1       -114.5      34.4                19.0       7650.0          1901.0   \n",
              "2       -114.6      33.7                17.0        720.0           174.0   \n",
              "3       -114.6      33.6                14.0       1501.0           337.0   \n",
              "4       -114.6      33.6                20.0       1454.0           326.0   \n",
              "..         ...       ...                 ...          ...             ...   \n",
              "995     -117.1      32.5                 8.0       6533.0          1217.0   \n",
              "996     -117.1      34.6                 6.0       5110.0          1044.0   \n",
              "997     -117.1      34.2                22.0       4397.0           931.0   \n",
              "998     -117.1      34.0                24.0       4144.0           826.0   \n",
              "999     -117.1      33.6                 6.0       1868.0           289.0   \n",
              "\n",
              "     population  households  median_income  median_house_value  \n",
              "0        1015.0       472.0            1.5                66.9  \n",
              "1        1129.0       463.0            1.8                80.1  \n",
              "2         333.0       117.0            1.7                85.7  \n",
              "3         515.0       226.0            3.2                73.4  \n",
              "4         624.0       262.0            1.9                65.5  \n",
              "..          ...         ...            ...                 ...  \n",
              "995      4797.0      1177.0            4.0               144.4  \n",
              "996      1938.0       724.0            3.2               112.8  \n",
              "997      1145.0       445.0            4.5               108.4  \n",
              "998      2127.0       772.0            2.5                96.0  \n",
              "999       750.0       247.0            4.4               307.6  \n",
              "\n",
              "[1000 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a517a47c-f8d9-417b-a123-25605da33383\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.3</td>\n",
              "      <td>34.2</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>66.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.5</td>\n",
              "      <td>34.4</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>80.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.7</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.7</td>\n",
              "      <td>85.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.6</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>73.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.6</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>65.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>32.5</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6533.0</td>\n",
              "      <td>1217.0</td>\n",
              "      <td>4797.0</td>\n",
              "      <td>1177.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>144.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>34.6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5110.0</td>\n",
              "      <td>1044.0</td>\n",
              "      <td>1938.0</td>\n",
              "      <td>724.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>112.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>34.2</td>\n",
              "      <td>22.0</td>\n",
              "      <td>4397.0</td>\n",
              "      <td>931.0</td>\n",
              "      <td>1145.0</td>\n",
              "      <td>445.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>108.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>4144.0</td>\n",
              "      <td>826.0</td>\n",
              "      <td>2127.0</td>\n",
              "      <td>772.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>96.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>33.6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1868.0</td>\n",
              "      <td>289.0</td>\n",
              "      <td>750.0</td>\n",
              "      <td>247.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>307.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a517a47c-f8d9-417b-a123-25605da33383')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a517a47c-f8d9-417b-a123-25605da33383 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a517a47c-f8d9-417b-a123-25605da33383');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## to fix this problem, we can shuffle the examples in the training set before splitting the examples into a training set and a validation set.\n",
        "## this can be done following these two steps:\n",
        "## 1 - shuffle the data in the training set by adding this line anywhere before the call to train_model:\n",
        "#shuffled_train_df = train_df.reindex(mp.random.permutation(train_df.index))\n",
        "\n",
        "## 2 - pass shuffled_train_df (instead of train_df) as the second argument to train_model, so it's like\n",
        "#epochs, rmse, history = train_model(my_model, shuffled_train_df, my_feature,\n",
        "#                                    my_label, epochs, batch_size.\n",
        "#                                    validation_split)\n"
      ],
      "metadata": {
        "id": "ZuzmGaykloil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# so, with above changes, what we have now is\n",
        "learning_rate = 0.08\n",
        "epochs = 70\n",
        "batch_size = 100\n",
        "\n",
        "# Split the original training set into a reduced training set and a\n",
        "# validation set. \n",
        "validation_split = 0.2\n",
        "\n",
        "# Identify the feature and the label.\n",
        "my_feature = \"median_income\"    # the median income on a specific city block.\n",
        "my_label = \"median_house_value\" # the median house value on a specific city block.\n",
        "# That is, you're going to create a model that predicts house value based solely on the neighborhood's median income.  \n",
        "\n",
        "# Shuffle the examples.\n",
        "shuffled_train_df = train_df.reindex(np.random.permutation(train_df.index)) \n",
        "\n",
        "# Invoke the functions to build and train the model. Train on the shuffled training set.\n",
        "my_model = build_model(learning_rate)\n",
        "epochs, rmse, history = train_model(my_model, shuffled_train_df, my_feature, \n",
        "                                    my_label, epochs, batch_size, \n",
        "                                    validation_split)\n",
        "\n",
        "plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"], \n",
        "                    history[\"val_root_mean_squared_error\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_HYJUm2OmluN",
        "outputId": "6576fabe-3920-47f2-eb93-033355443f7d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "136/136 [==============================] - 1s 3ms/step - loss: 43559.6758 - root_mean_squared_error: 208.7095 - val_loss: 34185.4414 - val_root_mean_squared_error: 184.8931\n",
            "Epoch 2/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 25458.9570 - root_mean_squared_error: 159.5586 - val_loss: 19068.9668 - val_root_mean_squared_error: 138.0904\n",
            "Epoch 3/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 13668.7422 - root_mean_squared_error: 116.9134 - val_loss: 10213.2979 - val_root_mean_squared_error: 101.0609\n",
            "Epoch 4/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 7983.4541 - root_mean_squared_error: 89.3502 - val_loss: 7270.8623 - val_root_mean_squared_error: 85.2693\n",
            "Epoch 5/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6972.2451 - root_mean_squared_error: 83.5000 - val_loss: 7200.1401 - val_root_mean_squared_error: 84.8536\n",
            "Epoch 6/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6968.2124 - root_mean_squared_error: 83.4758 - val_loss: 7200.4902 - val_root_mean_squared_error: 84.8557\n",
            "Epoch 7/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6966.2700 - root_mean_squared_error: 83.4642 - val_loss: 7202.1494 - val_root_mean_squared_error: 84.8655\n",
            "Epoch 8/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6968.0776 - root_mean_squared_error: 83.4750 - val_loss: 7203.9160 - val_root_mean_squared_error: 84.8759\n",
            "Epoch 9/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.9219 - root_mean_squared_error: 83.4741 - val_loss: 7201.9102 - val_root_mean_squared_error: 84.8641\n",
            "Epoch 10/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.9141 - root_mean_squared_error: 83.4740 - val_loss: 7201.1113 - val_root_mean_squared_error: 84.8594\n",
            "Epoch 11/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6968.3745 - root_mean_squared_error: 83.4768 - val_loss: 7203.9961 - val_root_mean_squared_error: 84.8764\n",
            "Epoch 12/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6968.5166 - root_mean_squared_error: 83.4776 - val_loss: 7202.3242 - val_root_mean_squared_error: 84.8665\n",
            "Epoch 13/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6966.8848 - root_mean_squared_error: 83.4679 - val_loss: 7200.9453 - val_root_mean_squared_error: 84.8584\n",
            "Epoch 14/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.7178 - root_mean_squared_error: 83.4729 - val_loss: 7205.5518 - val_root_mean_squared_error: 84.8855\n",
            "Epoch 15/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6968.6230 - root_mean_squared_error: 83.4783 - val_loss: 7203.5972 - val_root_mean_squared_error: 84.8740\n",
            "Epoch 16/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.7378 - root_mean_squared_error: 83.4730 - val_loss: 7206.1401 - val_root_mean_squared_error: 84.8890\n",
            "Epoch 17/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6968.1235 - root_mean_squared_error: 83.4753 - val_loss: 7200.8081 - val_root_mean_squared_error: 84.8576\n",
            "Epoch 18/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.6353 - root_mean_squared_error: 83.4724 - val_loss: 7206.2778 - val_root_mean_squared_error: 84.8898\n",
            "Epoch 19/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6966.3335 - root_mean_squared_error: 83.4646 - val_loss: 7200.7363 - val_root_mean_squared_error: 84.8572\n",
            "Epoch 20/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6968.0771 - root_mean_squared_error: 83.4750 - val_loss: 7205.0195 - val_root_mean_squared_error: 84.8824\n",
            "Epoch 21/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.2734 - root_mean_squared_error: 83.4702 - val_loss: 7204.2212 - val_root_mean_squared_error: 84.8777\n",
            "Epoch 22/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6966.9731 - root_mean_squared_error: 83.4684 - val_loss: 7206.8418 - val_root_mean_squared_error: 84.8931\n",
            "Epoch 23/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6966.2104 - root_mean_squared_error: 83.4638 - val_loss: 7213.1675 - val_root_mean_squared_error: 84.9304\n",
            "Epoch 24/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6966.6357 - root_mean_squared_error: 83.4664 - val_loss: 7201.8198 - val_root_mean_squared_error: 84.8635\n",
            "Epoch 25/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.8325 - root_mean_squared_error: 83.4735 - val_loss: 7204.1963 - val_root_mean_squared_error: 84.8775\n",
            "Epoch 26/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6968.3066 - root_mean_squared_error: 83.4764 - val_loss: 7204.4048 - val_root_mean_squared_error: 84.8788\n",
            "Epoch 27/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6968.3613 - root_mean_squared_error: 83.4767 - val_loss: 7201.6694 - val_root_mean_squared_error: 84.8626\n",
            "Epoch 28/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.5615 - root_mean_squared_error: 83.4719 - val_loss: 7200.9385 - val_root_mean_squared_error: 84.8583\n",
            "Epoch 29/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.7637 - root_mean_squared_error: 83.4731 - val_loss: 7205.9482 - val_root_mean_squared_error: 84.8879\n",
            "Epoch 30/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6968.1562 - root_mean_squared_error: 83.4755 - val_loss: 7204.4175 - val_root_mean_squared_error: 84.8788\n",
            "Epoch 31/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6965.9644 - root_mean_squared_error: 83.4624 - val_loss: 7214.8315 - val_root_mean_squared_error: 84.9402\n",
            "Epoch 32/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6968.4292 - root_mean_squared_error: 83.4771 - val_loss: 7205.0708 - val_root_mean_squared_error: 84.8827\n",
            "Epoch 33/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.8325 - root_mean_squared_error: 83.4735 - val_loss: 7201.2695 - val_root_mean_squared_error: 84.8603\n",
            "Epoch 34/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.4541 - root_mean_squared_error: 83.4713 - val_loss: 7200.9351 - val_root_mean_squared_error: 84.8583\n",
            "Epoch 35/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.8452 - root_mean_squared_error: 83.4736 - val_loss: 7201.1411 - val_root_mean_squared_error: 84.8595\n",
            "Epoch 36/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6968.1499 - root_mean_squared_error: 83.4754 - val_loss: 7202.7432 - val_root_mean_squared_error: 84.8690\n",
            "Epoch 37/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.0200 - root_mean_squared_error: 83.4687 - val_loss: 7201.0059 - val_root_mean_squared_error: 84.8587\n",
            "Epoch 38/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6966.8599 - root_mean_squared_error: 83.4677 - val_loss: 7204.4331 - val_root_mean_squared_error: 84.8789\n",
            "Epoch 39/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.0894 - root_mean_squared_error: 83.4691 - val_loss: 7203.0430 - val_root_mean_squared_error: 84.8707\n",
            "Epoch 40/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6968.3560 - root_mean_squared_error: 83.4767 - val_loss: 7202.3853 - val_root_mean_squared_error: 84.8669\n",
            "Epoch 41/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.7529 - root_mean_squared_error: 83.4731 - val_loss: 7202.2505 - val_root_mean_squared_error: 84.8661\n",
            "Epoch 42/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6968.3516 - root_mean_squared_error: 83.4766 - val_loss: 7203.1094 - val_root_mean_squared_error: 84.8711\n",
            "Epoch 43/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.7949 - root_mean_squared_error: 83.4733 - val_loss: 7206.7109 - val_root_mean_squared_error: 84.8923\n",
            "Epoch 44/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6966.0552 - root_mean_squared_error: 83.4629 - val_loss: 7213.8916 - val_root_mean_squared_error: 84.9346\n",
            "Epoch 45/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.5205 - root_mean_squared_error: 83.4717 - val_loss: 7201.5352 - val_root_mean_squared_error: 84.8619\n",
            "Epoch 46/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.2930 - root_mean_squared_error: 83.4703 - val_loss: 7203.0371 - val_root_mean_squared_error: 84.8707\n",
            "Epoch 47/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6965.9072 - root_mean_squared_error: 83.4620 - val_loss: 7201.0771 - val_root_mean_squared_error: 84.8592\n",
            "Epoch 48/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.4795 - root_mean_squared_error: 83.4714 - val_loss: 7201.2578 - val_root_mean_squared_error: 84.8602\n",
            "Epoch 49/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6966.4414 - root_mean_squared_error: 83.4652 - val_loss: 7209.6353 - val_root_mean_squared_error: 84.9096\n",
            "Epoch 50/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.9883 - root_mean_squared_error: 83.4745 - val_loss: 7206.1973 - val_root_mean_squared_error: 84.8893\n",
            "Epoch 51/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.7178 - root_mean_squared_error: 83.4729 - val_loss: 7206.9565 - val_root_mean_squared_error: 84.8938\n",
            "Epoch 52/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6968.0835 - root_mean_squared_error: 83.4750 - val_loss: 7201.1270 - val_root_mean_squared_error: 84.8595\n",
            "Epoch 53/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6966.6084 - root_mean_squared_error: 83.4662 - val_loss: 7209.6719 - val_root_mean_squared_error: 84.9098\n",
            "Epoch 54/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6968.3701 - root_mean_squared_error: 83.4768 - val_loss: 7201.1240 - val_root_mean_squared_error: 84.8594\n",
            "Epoch 55/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.3506 - root_mean_squared_error: 83.4707 - val_loss: 7204.2378 - val_root_mean_squared_error: 84.8778\n",
            "Epoch 56/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6966.7632 - root_mean_squared_error: 83.4671 - val_loss: 7211.6323 - val_root_mean_squared_error: 84.9213\n",
            "Epoch 57/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6968.3667 - root_mean_squared_error: 83.4767 - val_loss: 7208.0605 - val_root_mean_squared_error: 84.9003\n",
            "Epoch 58/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.9062 - root_mean_squared_error: 83.4740 - val_loss: 7204.1660 - val_root_mean_squared_error: 84.8774\n",
            "Epoch 59/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6968.4082 - root_mean_squared_error: 83.4770 - val_loss: 7203.1631 - val_root_mean_squared_error: 84.8715\n",
            "Epoch 60/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6964.6123 - root_mean_squared_error: 83.4543 - val_loss: 7215.6904 - val_root_mean_squared_error: 84.9452\n",
            "Epoch 61/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.7617 - root_mean_squared_error: 83.4731 - val_loss: 7201.1328 - val_root_mean_squared_error: 84.8595\n",
            "Epoch 62/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6968.1802 - root_mean_squared_error: 83.4756 - val_loss: 7204.7720 - val_root_mean_squared_error: 84.8809\n",
            "Epoch 63/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.6875 - root_mean_squared_error: 83.4727 - val_loss: 7200.8882 - val_root_mean_squared_error: 84.8580\n",
            "Epoch 64/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.8765 - root_mean_squared_error: 83.4738 - val_loss: 7203.5483 - val_root_mean_squared_error: 84.8737\n",
            "Epoch 65/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.2368 - root_mean_squared_error: 83.4700 - val_loss: 7201.6265 - val_root_mean_squared_error: 84.8624\n",
            "Epoch 66/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.0366 - root_mean_squared_error: 83.4688 - val_loss: 7202.7207 - val_root_mean_squared_error: 84.8689\n",
            "Epoch 67/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.7910 - root_mean_squared_error: 83.4733 - val_loss: 7201.2856 - val_root_mean_squared_error: 84.8604\n",
            "Epoch 68/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6968.0439 - root_mean_squared_error: 83.4748 - val_loss: 7203.3379 - val_root_mean_squared_error: 84.8725\n",
            "Epoch 69/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.7725 - root_mean_squared_error: 83.4732 - val_loss: 7201.1201 - val_root_mean_squared_error: 84.8594\n",
            "Epoch 70/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6967.8330 - root_mean_squared_error: 83.4735 - val_loss: 7205.4419 - val_root_mean_squared_error: 84.8849\n",
            "76.1043701171875\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxcVZn/8c/T1VvSSUNImiULJtEQhIQsNAFZNBFUBIbIpuQFIwF+bBNBmd8IwqjgaEacwWWYEfyBLOowiaCCIJsSkTgwCglrwjJECNJhyQJkT3qp5/fHPVV9u9JdfbvTVdWd+r5fXa+uunWX5966dZ865957jrk7IiIiABWlDkBERPoPJQUREclSUhARkSwlBRERyVJSEBGRrMpSB7AzRowY4WPHji11GCIiA8rSpUvXuntDZ+8N6KQwduxYlixZUuowREQGFDN7vav3VH0kIiJZSgoiIpKlpCAiIlkD+pyCiBRHS0sLTU1NbNu2rdShSA/U1tYyevRoqqqqEk9TsKRgZrcAJwCr3X1SbPjFwDygDbjP3S8Lw68Azg3DL3H3hwoVm4j0TFNTE0OHDmXs2LGYWanDkQTcnXXr1tHU1MS4ceMST1fI6qPbgGPjA8xsFjAbmOLuBwLXhuEHAKcDB4ZprjezVAFjE5Ee2LZtG8OHD1dCGEDMjOHDh/e4dFewpODui4F3cwZfBFzj7tvDOKvD8NnAQnff7u6vASuAGYWKTUR6Tglh4OnNZ1bsE837AUeZ2Z/N7FEzOyQMHwW8ERuvKQzbgZmdb2ZLzGzJmjVrehXES29v4Lu/fZl3Nzf3anoRkV1VsZNCJbAHcBjwZeAO62Eqc/cb3b3R3RsbGjq9Ia9br67ZzL//fgWrN+qkmchAsG7dOqZOncrUqVPZe++9GTVqVPZ1c3P+H3dLlizhkksu6XYZhx9+eJ/E+oc//IETTjihT+ZVCsW++qgJ+JVHPfs8YWZpYASwChgTG290GFYQg6qj0xVbmtsKtQgR6UPDhw/nmWeeAeDqq69myJAh/MM//EP2/dbWViorOz+cNTY20tjY2O0yHn/88b4JdoArdknhbmAWgJntB1QDa4F7gNPNrMbMxgETgCcKFcSgqigpbFNSEBmw5s6dy4UXXsihhx7KZZddxhNPPMFHPvIRpk2bxuGHH87LL78MdPzlfvXVV3POOecwc+ZMxo8fz3XXXZed35AhQ7Ljz5w5k1NPPZX999+fM844g0wPlffffz/7778/Bx98MJdcckmPSgQLFixg8uTJTJo0icsvvxyAtrY25s6dy6RJk5g8eTLf//73Abjuuus44IADOOiggzj99NN3fmP1QCEvSV0AzARGmFkTcBVwC3CLmS0DmoGzQqlhuZndAbwAtALz3L1gR+xMUtjaoqQg0lPfuHc5L7y5oU/necDIeq76mwN7PF1TUxOPP/44qVSKDRs28Mc//pHKykoefvhhrrzySn75y1/uMM1LL73EI488wsaNG5k4cSIXXXTRDtfxP/300yxfvpyRI0dyxBFH8Nhjj9HY2MgFF1zA4sWLGTduHHPmzEkc55tvvsnll1/O0qVLGTZsGJ/85Ce5++67GTNmDKtWrWLZsmUAvP/++wBcc801vPbaa9TU1GSHFUshrz6a4+77uHuVu49295vdvdndz3T3Se4+3d1/Hxt/vrt/0N0nuvsDhYoLYLCqj0R2CaeddhqpVPR9Xr9+PaeddhqTJk3i0ksvZfny5Z1Oc/zxx1NTU8OIESPYc889eeedd3YYZ8aMGYwePZqKigqmTp3KypUreemllxg/fnz2mv+eJIUnn3ySmTNn0tDQQGVlJWeccQaLFy9m/PjxvPrqq1x88cU8+OCD1NfXA3DQQQdxxhln8J//+Z9dVosVSlne0VyrkoJIr/XmF32h1NXVZZ9/7WtfY9asWdx1112sXLmSmTNndjpNTU1N9nkqlaK1tbVX4/SFYcOG8eyzz/LQQw/xox/9iDvuuINbbrmF++67j8WLF3Pvvfcyf/58nn/++aIlh7Js+yhTUtimpCCyy1i/fj2jRkVXst922219Pv+JEyfy6quvsnLlSgB+/vOfJ552xowZPProo6xdu5a2tjYWLFjAxz72MdauXUs6neaUU07hW9/6Fk899RTpdJo33niDWbNm8Z3vfIf169ezadOmPl+frpRlSUFXH4nsei677DLOOussvvWtb3H88cf3+fwHDRrE9ddfz7HHHktdXR2HHHJIl+MuWrSI0aNHZ1/feeedXHPNNcyaNQt35/jjj2f27Nk8++yznH322aTTaQC+/e1v09bWxplnnsn69etxdy655BJ23333Pl+frljmrPpA1NjY6L3pZCeddsZfeT9fPHoCl35ivwJEJrJrefHFF/nwhz9c6jBKbtOmTQwZMgR3Z968eUyYMIFLL7201GHl1dlnZ2ZL3b3T63TLsvqoosKorarQOQUR6ZGbbrqJqVOncuCBB7J+/XouuOCCUofU58qy+giiy1K3qvpIRHrg0ksv7fclg51VliUFCElBJQURkQ7KNylUq6QgIpKrvJOCSgoiIh2Ub1LQOQURkR2Ub1KormSLSgoiA8KsWbN46KGOPfT+4Ac/4KKLLupympkzZ5K5ZP24447rtA2hq6++mmuvvTbvsu+++25eeOGF7Ouvf/3rPPzwwz0Jv1P9tYnt8k0KVRVqJVVkgJgzZw4LFy7sMGzhwoWJ2x+6//77e30DWG5S+Kd/+ieOOeaYXs1rICjjpKBzCiIDxamnnsp9992X7VBn5cqVvPnmmxx11FFcdNFFNDY2cuCBB3LVVVd1Ov3YsWNZu3YtAPPnz2e//fbjyCOPzDavDdE9CIcccghTpkzhlFNOYcuWLTz++OPcc889fPnLX2bq1Kn85S9/Ye7cufziF78AojuXp02bxuTJkznnnHPYvn17dnlXXXUV06dPZ/Lkybz00kuJ17XUTWyX730K1ZVq5kKkNx74Crz9fN/Oc+/J8Olrunx7jz32YMaMGTzwwAPMnj2bhQsX8tnPfhYzY/78+eyxxx60tbVx9NFH89xzz3HQQQd1Op+lS5eycOFCnnnmGVpbW5k+fToHH3wwACeffDLnnXceAF/96le5+eabufjiiznxxBM54YQTOPXUUzvMa9u2bcydO5dFixax33778fnPf54bbriBL33pSwCMGDGCp556iuuvv55rr72WH//4x91uhv7QxHZZlxTUIJ7IwBGvQopXHd1xxx1Mnz6dadOmsXz58g5VPbn++Mc/ctJJJzF48GDq6+s58cQTs+8tW7aMo446ismTJ3P77bd32fR2xssvv8y4cePYb7+oqZyzzjqLxYsXZ98/+eSTATj44IOzjeh1pz80sV3GJYWomQt3p4fdRIuUtzy/6Atp9uzZXHrppTz11FNs2bKFgw8+mNdee41rr72WJ598kmHDhjF37ly2betd3+tz587l7rvvZsqUKdx222384Q9/2Kl4M81v90XT28VsYrtsSwqDqytpSzvNbelShyIiCQwZMoRZs2ZxzjnnZEsJGzZsoK6ujt1224133nmHBx7I3z/XRz/6Ue6++262bt3Kxo0buffee7Pvbdy4kX322YeWlhZuv/327PChQ4eycePGHeY1ceJEVq5cyYoVKwD42c9+xsc+9rGdWsf+0MR2IbvjvAU4AVjt7pPCsKuB84A1YbQr3f3+8N4VwLlAG3CJuz+0w0z7UG22n+Y0NZWpQi5KRPrInDlzOOmkk7LVSFOmTGHatGnsv//+jBkzhiOOOCLv9NOnT+dzn/scU6ZMYc899+zQ/PU3v/lNDj30UBoaGjj00EOzieD000/nvPPO47rrrsueYAaora3l1ltv5bTTTqO1tZVDDjmECy+8sEfr0x+b2C5Y09lm9lFgE/DTnKSwyd2vzRn3AGABMAMYCTwM7NddP829bTob4L/+/FeuvOt5/nTF0ey9W22v5iFSLtR09sDVb5rOdvfFwLsJR58NLHT37e7+GrCCKEEUTHs/zYXpZk9EZCAqxTmFL5jZc2Z2i5kNC8NGAW/ExmkKw3ZgZueb2RIzW7JmzZrORklE/TSLiOyo2EnhBuCDwFTgLeC7PZ2Bu9/o7o3u3tjQ0NDrQAapn2aRHhnIvTSWq958ZkVNCu7+jru3uXsauIn2KqJVwJjYqKPDsIIZrH6aRRKrra1l3bp1SgwDiLuzbt06amt7ds60qPcpmNk+7v5WeHkSsCw8vwf4LzP7HtGJ5gnAE4WMZVCm+khJQaRbo0ePpqmpiZ2pspXiq62t7XB1UxKFvCR1ATATGGFmTcBVwEwzmwo4sBK4AMDdl5vZHcALQCswr7srj3ZWpvpI5xREuldVVcW4ceNKHYYUQcGSgrt31nzhzXnGnw/ML1Q8uVRSEBHZUdne0TxIVx+JiOygfJOCTjSLiOygbJNCTWUFZrokVUQkrmyTgpmpn2YRkRxlmxQguldB/TSLiLQr66RQW5VSP80iIjFlnRTUT7OISEd5k4KZpczs2nzjDGSDq1O6+khEJCZvUgh3FR9ZpFiKrlYlBRGRDpLc0fy0md0D3Alszgx0918VLKoiGVSd4t3NzaUOQ0Sk30iSFGqBdcDHY8McGPBJYXB1iqb3VFIQEcnoNim4+9nFCKQUanWfgohIB91efWRmo83sLjNbHR6/NLOetcXaTw2qSumOZhGRmCSXpN5K1N/ByPC4Nwwb8HT1kYhIR0mSQoO73+rureFxG9D7fjD7kcx9CupNSkQkkiQprDOzM8M9CykzO5PoxPOAVxtaSt3emi5xJCIi/UOSpHAO8FngbeAt4FRglzj5PLhKzWeLiMR1e0cz8M/ufqK7N7j7nu7+GXf/a3czNrNbwonpZZ2893/NzM1sRHhtZnadma0ws+fMbHqv16gH1CWniEhHSe5o/oCZVfdi3rcBx+YONLMxwCeBeGL5NDAhPM4HbujF8nqsVl1yioh0kOTmtVeBx8JdzfE7mr+XbyJ3X2xmYzt56/vAZcCvY8NmAz/16Izvn8xsdzPbx93fShBfrw2ujlZfSUFEJJIkKfwlPCqAoTuzMDObDaxy92fNLP7WKOCN2OumMGyHpGBm5xOVJth33313Jhz10ywikiNvUgjnFPZz9zN2dkFmNhi4kqjqqNfc/UbgRoDGxsadupa0vZ/m1p2ZjYjILqOQ5xRyfRAYBzxrZiuB0cBTZrY3sAoYExt3dBhWUJmSgu5qFhGJFOycQi53fx7YM/M6JIZGd18b5v0FM1sIHAqsL/T5BNDVRyIiuZLcp/AX4De0n1PIPPIyswXA/wATzazJzM7NM/r9RMlnBXAT8HcJ4uq91xbDrccxZFuUd3SfgohIJEkrqd/IHWZmSaab0837Y2PPHZjX3Tz7zLYN8Ppj1LauB3T1kYhIRpclBTP779jzn+W8/UTBIiqG6joAatNbAZ1TEBHJyFd9VBd7PinnPWMgqx4CQFXbViorTNVHIiJBvqTgXTzv7PXAEkoKNG/OtpQqIiL5zynsbmYnESWO3c3s5DDcgN0KHlkhxZJCbfUQVR+JiAT5ksKjwImx538Te29xwSIqhlhSUEc7IiLtukwKu3LfzO1JYVNUfaSkICICJLtPYddTWQtWEVUf6ZyCiEhWeSYFs+gKpFB9pJKCiEikPJMCRFVImeojlRRERIA85xRiVxt1yt1/1ffhFFF1Xbj6SElBRCQj39VHmauN9gQOB34fXs8CHgd2iaSg6iMRkXbdXn1kZr8FDsi0Wmpm+xB1tTmwhXMKg4aopCAikpHknMKYnGas3wF2rsuz/iB+TkElBRERIFl/CovM7CFgQXj9OeDhwoVUJNV10LKFQdUptremaUs7qYqB3aSTiMjOStIE9hdCcxcfDYNudPe7ChtWEYRzCvHe1+pqkuRIEZFdV9Kj4FPARnd/2MwGm9lQd99YyMAKripUH2X7aVZSEBHp9pyCmZ0H/AL4f2HQKODuQgZVFJmSQmW0CdQonohIshPN84AjgA0A7v4Ksb6Wu2Jmt5jZajNbFhv2TTN7zsyeMbPfmtnIMNzM7DozWxHen9671emB6jpIt1JXmQbUT7OICCRLCtvdvTnzInTFmaQ/hduAY3OG/au7H+TuU4n6ff56GP5pYEJ4nA/ckGD+Oyd0tDOkYhugfppFRCBZUnjUzK4EBpnZJ4A7gXu7m8jdFwPv5gzbEHtZR3tymQ381CN/Iuq/YZ8kK9BroaXUOrYD6qdZRASSJYXLgTXA88AFwP3AV3u7QDObb2ZvAGfQXlIYBbwRG60pDOts+vPNbImZLVmzZk1vw8gmhcFEJQWdUxAR6SYpmFkKeNHdb3L309z91PC8191xuvs/uvsY4HbgC72Y/kZ3b3T3xoaGht6Gka0+yiQFVR+JiHSTFNy9DXjZzApxB/PtwCnh+SpgTOy90WFY4YSSQq1HSUEnmkVEkt2nMAxYbmZPAJszA939xK4n6ZyZTQhXL0F0HuGl8Pwe4AtmthA4FFif07RG3wtJoca3ANVKCiIiJEsKX+vNjM1sATATGGFmTcBVwHFmNhFIA68DF4bR7weOA1YAW4DCdwUaqo9qfTtQzdbm1oIvUkSkv0vSzMWjvZmxu8/pZPDNXYzrRPdDFE8oKVS1bQGGsrU5XdTFi4j0R0nuaD7MzJ40s01m1mxmbWa2obvp+r2QFFItW6hOVaj6SESEZJek/gcwB3gFGAT8H+CHhQyqKEJSoHkzg6pTqj4SESFhH83uvgJIuXubu9/KjncqDzwVKaisVT/NIiIxSU40bzGzauAZM/sX4C0SJpN+L9MoXnWKrS06pyAikuTg/rdAiuhGs81E9xOckneKgSLWp4Kqj0REkl199Hp4uhX4RmHDKbLqIdk+FVR9JCKSICmY2Wt00iqqu48vSETFFCspbFFJQUQk0TmFxtjzWuA0YI/ChFNksXMKazdtL3U0IiIl1+05BXdfF3uscvcfAMcXIbbCqx6SLSmolVQRkWTVR/Fe0CqISg67RmfG1XXQkqk+UlIQEUlycP9u7HkrsBL4bEGiKbYOl6QqKYiIJLn6aFYxAimJWFJQ9ZGISLLqo7/P9767f6/vwimyqjpo2cLgSmhpc1ra0lSldo378kREeiPp1UeHEPV5APA3wBNEbSENbKH9o/pUCxB1tKOkICLlLElSGA1Md/eNAGZ2NXCfu59ZyMCKIiSFIRZdjrqtuY362qpSRiQiUlJJfhbvBTTHXjeHYQNf6GgnkxR0BZKIlLskJYWfAk+Y2V2AEXWjeVshgyqaTEmhQv00i4hAspvX5hN1j/kesA44292/3d10ZnaLma02s2WxYf9qZi+Z2XNmdpeZ7R577wozW2FmL5vZp3q3Oj0UksIglBRERCBPUjCzwWZWBeDuTwEPErWWOi7hvG9jx34XfgdMcveDgP8FrgjLOgA4HTgwTHO9maWSr0YvheqjwZmkoOojESlz+UoKDwJjAczsQ8D/AOOBeWZ2TXczdvfFwLs5w37r7pmW5/5EdBIboiqphe6+3d1fA1YAM3qwHr2TKSm4koKICORPCsPcPXPZ6VnAAne/GPg0fdP20TnAA+H5KOCN2HtNYdgOzOx8M1tiZkvWrFmzcxGEpFDjqj4SEYH8SSHeXPbHiap+cPdmYKe6KTOzfyRqMuP2nk7r7je6e6O7NzY0NOxMGNnqoxrfCqikICKS7+qj58zsWmAV8CHgtwDxk8O9YWZzgROAo909k3hWEfXoljE6DCusUFKobgtJQSUFESlz+UoK5wFric4rfNLdt4ThBwDX9mZhZnYscBlwYmx+EN0tfbqZ1ZjZOGAC0V3ThVVZA5aiui0KRUlBRMpdlyUFd98K7HBC2d0fBx7vbsZmtgCYCYwwsybgKqKrjWqA35kZwJ/c/UJ3X25mdwAvEFUrzXP3wh+hzaC6jsqQFHTzmoiUu4L1i+DuczoZfHOe8ecD8wsVT5eq67DmzdRWVailVBEpe2r9LdZPs040i0i5U1IISWFwdaWqj0Sk7CXpT2E/4MvAB+Lju/vHCxhX8YR+mutqUmze3tr9+CIiu7Ak5xTuBH4E3ATsej+lq+tg02rqa6vYsK2l1NGIiJRUkqTQ6u43FDySUgnVR/VDq1i9cVupoxERKakk5xTuNbO/M7N9zGyPzKPgkRVLddQlZ31tJRu2qvpIRMpbkpLCWeH/l2PDnKhxvIGvegg0b6J+kKqPRES6TQrunrSp7IEpU31UU8mGrS24O+HGOhGRspPo5jUzm0TUvEVtZpi7/7RQQRVVdR2kW9m91kk7bG5uY0hNwe7pExHp15JcknoVUXMVBwD3EzWd/d9E3XQOfFVRo3h7VEZVRxu2tigpiEjZSnKi+VTgaOBtdz8bmALsVtCoiim0lLp7ZTOAziuISFlLkhS2unsaaDWzemA1HZu5HtgySSEVkoKuQBKRMpaknmRJ6EPhJmApsImoa85dQ+hoZ2hqOxBVH4mIlKskVx/9XXj6IzN7EKh39+cKG1YRhZLCUAtJQdVHIlLGuq0+ssiZZvZ1d18JvG9mMwofWpGEpFBnKimIiCQ5p3A98BEg0z/CRuCHBYuo2EL10SCiLjk3bNM5BREpX0mSwqHuPg/YBuDu7wHVBY2qmEJJobJ1K4OrUyopiEhZS5IUWswsRdS0BWbWAKS7m8jMbjGz1Wa2LDbsNDNbbmZpM2vMGf8KM1thZi+b2ad6uB69F5ICzZvVUqqIlL0kSeE64C5gTzObT3Tj2j8nmO424NicYcuAk4HF8YFmdgBwOnBgmOb6kIgKL54UBqlRPBEpb0muPrrdzJYS3cBmwGfc/cUE0y02s7E5w14EOmtbaDaw0N23A6+Z2QpgBsW49LUiBZWDokbxVFIQkTLXZVLIaR57NbAg/p67v9uHcYwC/hR73RSGdRbX+cD5APvuu2/fLD3TKN4g9akgIuUtX0lhLdHBOVOfEv95X7Kms939RuBGgMbGRu+TmVYPDucUKlmxWtVHIlK+8iWF64BZwGNEpYT/dve+OQjvaBUdm84YHYYVh/pUEBEB8pxodvcvAVOJ+mj+W+BpM/sXMytE/wr3AKebWU2Y/wTgiQIsp3OZ6qPaqmyfCiIi5Sjv1UceeQS4DPgRcDZwTJIZm9kCohPFE82syczONbOTzKyJ6Ga4+8zsobCc5cAdwAvAg8A8d2/r7Ur1WPacQmW2TwURkXKU70RzHdFVQZ8DGoBfAQe7+1+TzNjd53Tx1l1djD8fmJ9k3n2ueghsWkN9bRWgPhVEpHzlO/KtBl4BFob/DjRmbjpz918VPrwiqa7LnlOAqFG8kQwqcVAiIsWXLyncSZQIJoZHnBOVHHYN1XXQsiVWUtAVSCJSnrpMCu4+t4hxlFbsnAKopVQRKV9JmrnY9VUPiUoK1dHm0GWpIlKulBQg2/5RfVVUbaSSgoiUqySd7NQkGTagZXtfi5q4UJ8KIlKukpQUOmuUbtfpoxmgKkoKVW3qU0FEylu++xT2JmqUbpCZTaO97aN6YHARYiuebPPZailVRMpbvktSPwXMJWqH6Hux4RuBKwsYU/GpTwURESD/Jak/AX5iZqe4+y+LGFPxhX6ao/aP6lRSEJGyleScwiIz+56ZLQmP75rZbgWPrJji1UdqKVVEyliSpHAzUZXRZ8NjA3BrIYMqug79NKv6SETKV5JW3z7o7qfEXn/DzJ4pVEAlka0+2qKSgoiUtSQlha1mdmTmhZkdAWwtXEglkHv1kfpUEJEylaSkcBHRCefdiC5LfRc4q6BRFVtlDVhqhz4V1Hy2iJSbbo967v4MMMXM6sPrDQWPqtjMQpecm6kfqj4VRKR8JWnmYjcz+x7we+D3u+TVR9BpnwoiIuUmyTmFW+jF1UdmdouZrTazZbFhe5jZ78zslfB/WBhuZnadma0ws+fMbHrvVmcn1O4GW99TnwoiUtaSJIUPuvtV7v5qeHwDGJ9gutuAY3OGfQVY5O4TgEXhNcCngQnhcT5wQ5Lg+1T9SNjwpvpUEJGyVrCrj9x9MdFJ6bjZwE/C858An4kN/6lH/gTsbmb7JIit72SSQq2qj0SkfBX76qO93P2t8PxtYK/wfBTwRmy8pjDsLXKY2flEpQn23XffXobRifpRsOkd6qujlyopiEg56rak4O7PuPsU4CBgMtAY/u8Uj24E6PHNAO5+o7s3untjQ0PDzobRrn4fwBnauhZQnwoiUp66TApmVm9mV5jZf5jZJ4hONn8eWEF0wrk33slUC4X/q8PwVcCY2Hijw7DiqR8FQNWmt9WngoiUrXwlhZ8BE4HngfOAR4DTgJPcfXYvl3cP7VVPZwG/jg3/fLgK6TBgfayaqTjqR0b/N6xSnwoiUrbynVMY7+6TAczsx0T1+/u6+7YkMzazBcBMYISZNQFXAdcAd5jZucDrtJc47geOIyqFbAHO7vmq7KRsUniT+kHDdUmqiJSlfEkh+1PZ3dvMrClpQgjTzOniraM7GdeBeUnnXRC1u0PVYNj4FvW101VSEJGylC8pTDGzTJMWRtQt54bw3N29vuDRFZNZuCx1FfWDqli9MXH+ExHZZeTreS1VzED6hcy9CnWVrFit6iMRKT9Jbl4rH/WjwjkFnWgWkfKkpBBXPxI2vsVuNRXqU0FEypKSQlz9SEi3smdqQ7ZPBRGRcqKkEBduYNvLoyabdAObiJQbJYW4cK/C8HSmqQslBREpL0oKcaGksHvrGkB9KohI+VFSiBs8HFLVDG2OmmRS9ZGIlBslhbhwA9vgbe8Aqj4SkfKjpJCrfhQ1W94GVFIQkfKjpJCrfiSVm6MGWtWngoiUGyWFXPUjsQ1vMri6QiUFESk7Sgq5ho6Etmb2rdmqcwoiUnaUFHKFexXG1byvS1JFpOwoKeQK9yrsW/m+SgoiUnaUFHKFksKoiveUFESk7JQkKZjZF81smZktN7MvhWF7mNnvzOyV8H9YKWJjyJ5gKfa2d1V9JCJlp+hJwcwmAecBM4ApwAlm9iHgK8Aid58ALAqvi68iBUP3ocHXqaQgImWnFCWFDwN/dvct7t4KPAqcDMwGfhLG+QnwmRLEFqkfyR5ta9WngoiUnVIkhWXAUWY23MwGA8cBYyInt04AAA4SSURBVIC93P2tMM7bwF6dTWxm55vZEjNbsmbNmsJEWD+S3VrWqE8FESk7RU8K7v4i8B3gt8CDwDNAW844DnT6E93db3T3RndvbGhoKEyQ9aOo2/4O4KzesK0wyxAR6YdKcqLZ3W9294Pd/aPAe8D/Au+Y2T4A4f/qUsQGQP1Iqtq2Us8WHluxtmRhiIgUW6muPtoz/N+X6HzCfwH3AGeFUc4Cfl2K2IDsZakHD9vCopdKl5tERIqtVPcp/NLMXgDuBea5+/vANcAnzOwV4JjwujTCDWzHjGrj8b+sY0uzLk0VkfJQWYqFuvtRnQxbBxxdgnB2FEoKM4Zvo7k1zeMr1nHMAZ2e9xYR2aXojubODN0bMMZXr6euOsXvX1YVkoiUByWFzqSqYMhepDa9yVETGnjkpdW6X0FEyoKSQlfqR8KGN/n4/nvy1vptvPjWxlJHJCJScEoKXQlJYeb+0b0Qj6gKSUTKgJJCV+pHwYY32XNoLQeN3o1FL75T6ohERApOSaEr9SNh+3p48Tcc+8Fann7jfd7d3FzqqERECqokl6QOCKMPgcpa+PkZXIQxq2oM7915L3t8cELH8dyjBw6eDq/TsdfpaDyrACz6bxVgFmZg7c/TbWGa8D/zXnbanOdYNG66tf3hnjNeRXscmfgAUpVQUQkVVVHLsOk2SLdAW0v0HI/eT1WFcSqj6ePLyrZEEluH+DZIZ2IL821rjoZVDQqPwdE2rkjlxJju5AMJ61KRat+G8eXGt0VbS9gW8W0YtldbM7RshdZt0f90G1TWRPFU1kaPVCVYKmyfVPuy8op9/nj755D9zGOfcbo19hmz42caXyeIvc7Z74jte+m2sP6xz6ituf2R3e6Dobou+l+R6rjvxrdzfB/qsNw2aN0ezbN1e7QdIWynVPv2yl6YEf5bKuxzVdE+ZRVh+u3QFuZnqfAZVEOqpn2f87b29WtrbR+/tTkallluPIaKzGeYu6+E9WnZCi2boXkLtGyJhtcMibZNdfjv3nHZmfXI7he5+21mnPh33XI+q8xmzvkux783ns7Zdyrat326tX0fGvdR2O9T+XbKXlFS6MrYI+Dy12HVUnzlY6x/9DdMe/0uWJmwLaT4gQvY4aDR9YQ5O0IsweRbVkU4yGOxZWV2sIpoB87O12MHzlizU5YKSSDMJ3Mw95xGATOJJPvlD+vj3vGgbRYSS3UsuaSgZVv0RWzZGr6Q3nG9OyRN2uedOZAm2hZVnWxDj2KpCgf/qkHROrduCweorVFsme2S3pmbFo0uP+f45xEFuOO+kXtQ7WoZmYNH9oBYGR0IK6rat3tlTbSszPbOHgi947y6XV5QURkdtCvDA2JJqS0kxPg8idavrSXapzLbtSLElqqOHt4WHehbt0UH/nhsmfWLr1OqKhyYY8kwfhBPZ57HPv/M+lUOgurB7UkSYPtGaN4EzZvbk1182ZBnv7AdP89O5dkvsvOJ/cDKlfmeWyqKW0mhyKpqYewRVIw9gl+u+RQXLH+TJVfMpCqVU+uW+8u1s192cR7/4uceUBNMGz+AZH4N9VY6Hfu11cV8kozTW5lt0d16506zwwG0D7ZFZ9KdJaGQxHJlf2HHD4be/plBss+4GDJxdba/5sYcZ+Eg2RfLzvdZZZbf2Q+EYki35V92Ot0xvq5Kc11t4+z74bvc1Xzi+3qRtoWSQkJHf3hP7lzaxNJVWzhs/PCdm1nmg+3NB2zW/qulL1RU0O2ppSTj9Favt0GRDhQ7u+7ZWPvZ6bt827DQMSf5/Pp6P++p7hJfkv2iu/VMso7F3NcDJYWEjpzQQFXK+PwtT1BbWUFlqoIKMyorLPrxZO3/Hc8m+HTCm95yR/MuipiGUWFgYXnx6dyjqbIFkZx5GNb9dzHzP4yY2SeNaL3S4cdjfL0sNv4O84vlP+vk13V8W8XXAXbcJnnn38l7nc0n97Myi9YlnQ7/O6yX5Z1/d8vKLC++fRIVBHM+x/i8csfNFY/XctYzsz92t11zp8n9jDqsm9HhvaT7e26M8fm4O+nc6nc67mM7FsY632Zx8e9DyoyKiuj7W1ER7Zlph7a005Zu3w+6ml+S/aKr70R73GEZeceKzS/n9RmHfYB5sz6UcOrklBQSGlJTyb+eOoXnV63P7jitaactnQ5fNsJB0zt+GUme6HMPmp2WJMMXNB2+CNiOB6/4AThbPentX4rsOVB2nH9GZn3CH+5ORfh2xtfLvesDYvZL2GEc3+HLkql+zqxHfJt1lkhy55+JobMxc+fjRAeczMEx7U7KDDMjVdEeQ+726rjc5Mvy7PbrJNF3MaP49o3PKxNLfPPFt0/u9ogfLNPh88vd1h3CyfnM0+4dD9y52ya+3fPs753tb7nbJVvLkv3R0/5DJD5ufD0z27D9+9b1D4/49yHzubelnTaPvsc4VFQYKYv+V1gUR+42zt3OXcn3nYjH0v4jrOt5dbWscSPq8k/US0oKPfCZaaP4zLRRpQ5DRKRg+llFp4iIlJKSgoiIZCkpiIhIlpKCiIhklaqP5kvNbLmZLTOzBWZWa2bjzOzPZrbCzH5uZtWliE1EpJwVPSmY2SjgEqDR3ScBKeB04DvA9939Q8B7wLnFjk1EpNyVqvqoEhhkZpXAYOAt4OPAL8L7PwE+U6LYRETKVtGTgruvAq4F/kqUDNYDS4H33T3T0lQT0OkNAWZ2vpktMbMla9asKUbIIiJlo+g3r5nZMGA2MA54H7gTODbp9O5+I3BjmNcaM3s94aQjgLU9i7bkBlrMAy1eUMzFMtBiHmjxQs9i/kBXb5TijuZjgNfcfQ2Amf0KOALY3cwqQ2lhNLCquxm5e0PShZrZEndv7GXMJTHQYh5o8YJiLpaBFvNAixf6LuZSnFP4K3CYmQ22qBGco4EXgEeAU8M4ZwG/LkFsIiJlrRTnFP5MdEL5KeD5EMONwOXA35vZCmA4cHOxYxMRKXclaRDP3a8CrsoZ/Cowo4CLvbGA8y6UgRbzQIsXFHOxDLSYB1q80Ecxm+dr/1VERMqKmrkQEZEsJQUREcna5ZOCmR1rZi+HNpW+Uup4umJmt5jZajNbFhu2h5n9zsxeCf+HlTLGODMbY2aPmNkLoR2rL4bh/TnmWjN7wsyeDTF/Iwzv1+1umVnKzJ42s9+E1/093pVm9ryZPWNmS8KwfrtfAJjZ7mb2CzN7ycxeNLOP9OeYzWxi2L6ZxwYz+1JfxLxLJwUzSwE/BD4NHADMMbMDShtVl25jx5v4vgIscvcJwKLwur9oBf6vux8AHAbMC9u2P8e8Hfi4u08BpgLHmtlh9P92t74IvBh73d/jBZjl7lNj18335/0C4N+AB919f2AK0fbutzG7+8th+04FDga2AHfRFzG7+y77AD4CPBR7fQVwRanjyhPvWGBZ7PXLwD7h+T7Ay6WOMU/svwY+MVBiJmpz6yngUKK7QCs722dK/SC6kXMRUdtgvyHq1rffxhtiWgmMyBnWb/cLYDfgNcKFNwMh5pw4Pwk81lcx79IlBaL2k96Ive6yTaV+ai93fys8fxvYq5TBdMXMxgLTgD/Tz2MOVTHPAKuB3wF/IWG7WyXyA+AyIB1eD6d/xwtRv/W/NbOlZnZ+GNaf94txwBrg1lBN92Mzq6N/xxx3OrAgPN/pmHf1pLDL8Cj197vrh81sCPBL4EvuviH+Xn+M2d3bPCpyjya6L2b/EofUJTM7AVjt7ktLHUsPHenu04mqbeeZ2Ufjb/bD/aISmA7c4O7TgM3kVLv0w5gBCOeTTiRqQ66D3sa8qyeFVcCY2OtEbSr1I++Y2T4A4f/qEsfTgZlVESWE2939V2Fwv445w93fJ2pa5SOEdrfCW/1pHzkCONHMVgILiaqQ/o3+Gy+QbQkZd19NVM89g/69XzQBTR61tgBRiwvT6d8xZ3waeMrd3wmvdzrmXT0pPAlMCFdrVBMVs+4pcUw9cQ9RO1DQz9qDCu1W3Qy86O7fi73Vn2NuMLPdw/NBROdAXqSftrvl7le4+2h3H0u07/7e3c+gn8YLYGZ1ZjY085yovnsZ/Xi/cPe3gTfMbGIYlGmPrd/GHDOH9qoj6IuYS32SpAgnYY4D/peo7vgfSx1PnjgXEPUv0UL0y+VcovrjRcArwMPAHqWOMxbvkURF0+eAZ8LjuH4e80HA0yHmZcDXw/DxwBPACqJieE2pY+0k9pnAb/p7vCG2Z8NjeeY715/3ixDfVGBJ2DfuBoYNgJjrgHXAbrFhOx2zmrkQEZGsXb36SEREekBJQUREspQUREQkS0lBRESylBRERCRLSUEkDzNry2mNss8aRTOzsfFWcUX6g5J0xykygGz1qFkMkbKgkoJIL4Q+A/4l9BvwhJl9KAwfa2a/N7PnzGyRme0bhu9lZneFvhyeNbPDw6xSZnZT6N/ht+FOa5GSUVIQyW9QTvXR52LvrXf3ycB/ELVmCvDvwE/c/SDgduC6MPw64FGP+nKYTnS3L8AE4IfufiDwPnBKgddHJC/d0SySh5ltcvchnQxfSdRhz6uhYcC33X24ma0las++JQx/y91HmNkaYLS7b4/NYyzwO486RMHMLgeq3P1bhV8zkc6ppCDSe97F857YHnvehs7zSYkpKYj03udi//8nPH+cqEVTgDOAP4bni4CLINvRz27FClKkJ/SrRCS/QaGntowH3T1zWeowM3uO6Nf+nDDsYqIevL5M1JvX2WH4F4EbzexcohLBRUSt4or0KzqnINIL4ZxCo7uvLXUsIn1J1UciIpKlkoKIiGSppCAiIllKCiIikqWkICIiWUoKIiKSpaQgIiJZ/x+lZ5jGtpCKUQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# now we are going to use the test dataset to evaluate our model's performance:\n",
        "x_test = test_df[my_feature]\n",
        "y_test = test_df[my_label]\n",
        "\n",
        "results = my_model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-aIsP80uHX-",
        "outputId": "635bbe92-ada0-43c3-b030-f147c6390739"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30/30 [==============================] - 0s 1ms/step - loss: 7012.3813 - root_mean_squared_error: 83.7400\n",
            "[7012.38134765625, 83.73995971679688]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compare the root mean squared error of the model when evaluated on each of the three datasets:\n",
        "\n",
        "# training set: look for root_mean_squared_error in the final training epoch.\n",
        "# validation set: look for val_root_mean_squared_error in the final training epoch.\n",
        "# test set: run the preceding code cell and examine the root_mean_squared_error."
      ],
      "metadata": {
        "id": "vs54o6squyZ0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}